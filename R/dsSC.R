#' Test differential state using edgeR for single cell data
#'
#' \code{dsSC} run analysis for single cell data.
#'
#' @param d_sce A SingleCellExperiment object.
#' @param tree A phylo object. 
#' @param feature_on_row A logical value, TRUE or FALSE. If TRUE (default), the columns
#'   of the \code{assays} tables are treated as samples, and rows as entities
#'   (e.g. genes); otherwise, the other way around.
#' @param design A numeric matrix. It must be of full column rank. Defaults to
#'   use all columns of sample annotation data to create the design matrix. The
#'   sample annotation data is stored in the \code{colData} of \code{d_sce} when
#'   \code{feature_on_row = TRUE}; otherwise it is in the \code{rowData}. Note: Users
#'   should check whether the default created design matrix is exactly what they
#'   want or create their own design matrix using
#'   \code{\link[stats]{model.matrix}}.
#' @param contrast A numeric vector specifying one contrast of
#'   the linear model coefficients to be tested equal to zero. Its length
#'   must equal to the number of columns of design. If NULL, the last
#'   coefficient will be tested equal to zero.
#' @param normalize A logical value, TRUE or FALSE. The default is TRUE.
#' @param method Normalization method to be used. See
#'   \code{\link[edgeR]{calcNormFactors}} for more details.
#' @param prior_count average prior count to be added to observation to shrink
#'   the estimated log-fold-changes towards zero. See \code{prior.count} in
#'   \code{\link[edgeR]{glmFit}}
#' @param adjust_method A character string stating the method used to adjust
#'   p-values for multiple testing, passed on to \code{\link[stats]{p.adjust}}.
#'   It could be "bonferroni", "holm", "hochberg", "hommel", "BH", or "BY".
#' @param min_sample A numeric value. The minimum number of samples with
#'   non-zero value.
#' @param group_column The name of column that stores group information for
#'   samples.
#' @param message A logic value. If TRUE, the running process is printed out.
#'
#' @import TreeSummarizedExperiment
#' @importFrom edgeR DGEList calcNormFactors estimateDisp glmFit glmLRT
#'   topTags glmQLFit glmQLFTest
#' @importFrom methods is
#' @importFrom SummarizedExperiment assays colData rowData
#' @export
#' @return A data frame
#' \item{assays}{A list of tables}
#' \item{rowData}{It stores the information of rows in \code{assays}, and the
#' tables extracted from a \code{DGELRT} object that is generated by
#' \code{\link[edgeR:glmFit]{glmLRT}}. The later is stored as the internal part
#' of the \code{rowData}. More details or example could be found in the vignette
#' \code{Example of data analysis}}
#' \item{colData}{NULL}
#' \item{metadata}{
#'    \itemize{
#'    \item \code{assayNum} which elements in the \code{assays} have been
#'    used to run differential abundance analysis.
#'    \item \code{design} the design matrix as input.
#'    \item \code{contrast} the contrast vector as input.
#'    \item \code{output_glmFit} the output from \code{\link[edgeR]{glmFit}}. A
#'    object of \code{\link[edgeR]{DGEGLM-class}}
#'    }
#' }
#' @examples
#'
#' library(TreeSummarizedExperiment)
#' set.seed(1)
#' count <- matrix(rnbinom(300,size=1,mu=10),nrow=10)
#' colnames(count) <- paste(rep(LETTERS[1:3], each = 10), rep(1:10,3), sep = "_")
#' rownames(count) <- tinyTree$tip.label
#' count[1, ] <- 0
#' rowInf <- DataFrame(var1 = sample(letters[1:3], 10, replace = TRUE),
#'                     var2 = sample(c(TRUE, FALSE), 10, replace = TRUE))
#' colInf <- DataFrame(gg = factor(sample(1:3, 30, replace = TRUE)),
#'                     group = rep(LETTERS[1:3], each = 10))
#' lse <- TreeSummarizedExperiment(assays = list(count),
#'                                 rowData = rowInf,
#'                                 colData = colInf,
#'                                 rowTree = tinyTree)
#' nodes <- showNode(tree = tinyTree, only.leaf = FALSE)
#' d_sce <- aggValue(x = lse, rowLevel = nodes)
#'
#' out <- runEdgeR(d_sce = d_sce, feature_on_row = TRUE)
#'
#'
#'
dsSC <- function(d_sce, tree,
                 feature_on_row = TRUE, 
                 design = NULL, 
                 contrast = NULL,
                 normalize = TRUE, 
                 method = "TMM",
                 adjust_method = "BH", 
                 prior_count = 0.125,
                 min_sample = NULL,
                 group_column = "group",
                 message = FALSE) {
    
    # the alias of nodes
    alias <- names(assays(d_sce))
    res_list <- vector("list", length(alias))
    for (i in seq_along(alias)) {
        if (message) {
            message(i, " out of ", length(alias),
                    " nodes finished", "\r", appendLF = FALSE)
            flush.console()
        }
        
        res_i <-  .runDS(d_sce = d_sce, 
                         feature_on_row = feature_on_row, 
                         design = design, 
                         contrast = contrast,
                         normalize = normalize, 
                         method = method,
                         adjust_method = adjust_method, 
                         prior_count = prior_count,
                         assay_num = i, 
                         min_sample = min_sample,
                         group_column = group_column)
        
        if (!is.null(res_i)) {
            res_i <- res_i %>%
                mutate(nodeLab = alias[i],
                       gene_id = rownames(res_i)) %>%
                mutate(node = transNode(tree = tree, node = nodeLab))
        }
        
        res_list[[i]] <- res_i[, c("nodeLab", "node", "gene_id",
                                   "logFC", "logCPM", "F", 
                                   "PValue", "FDR")]
    }
    
    
    # combine all results as a data frame
    res_df <- do.call(rbind, res_list)
    
    # output
    out <- return(res_df)
    
}

.runDS <- function(d_sce, 
                  feature_on_row = TRUE, 
                  design = NULL, 
                  contrast = NULL,
                  normalize = TRUE, method = "TMM",
                  adjust_method = "BH", 
                  prior_count = 0.125,
                  assay_num = NULL, 
                  min_sample = NULL,
                  group_column = "group_id") {

    # analysis step
    if (feature_on_row) {
        # the count table
        count <- assays(d_sce)[[assay_num]]
        
        # experiment_info
        experiment_info <- colData(d_sce)
        
        # the sample size in the smaller group
        sz <- min(table(colData(d_sce)[[group_column]]))
    } else {
        # the count table
        count <- t(assays(d_sce)[[assay_num]])
        
        # experiment_info
        experiment_info <- rowData(d_sce)
        
        
        # the sample size in the smaller group
        sz <- min(table(rowData(d_sce)[[group_column]]))
    }
    
    
    
    
    # if min_sample is null, entities that have non-zero value in samples more
    # than the number of samples in the smaller group are kept; otherwise, the
    # non-zero samples should be above the specified min_sample
    if (!is.null(min_sample)) {
        sz <- min_sample
    } 
    isZ <- apply(count, 1, function(x) {
        sum(x > 0) < sz
    })
    rowF <- rownames(count)[isZ]
    count <- count[!isZ, ]
    
    # remove samples with library size equal to 0
    islib <- apply(count, 2, sum) > 0
    count <- count[, islib, drop = FALSE]
    
    # check whether there is data to run DS
    isGene <- nrow(count) > 0
    gr <- experiment_info[islib, group_column]
    isGroup <- length(unique(gr)) > 0
    
    if (isGene & isGroup) {
        # create the DGEList
        y <- DGEList(count, remove.zeros = FALSE)
        
        # do normalisation
        if (normalize) {
            y <- calcNormFactors(y, method = method)
        }
        
        # create design matrix
        if (is.null(design)) {
            design <- .designMatrix(data = experiment_info[islib, , drop = FALSE])
        }
        
        # estimate dispersion
        y <- estimateDisp(y, design = design)
        
        # build model
        #fit <- glmFit(y, design = design, prior.count = prior_count)
        fit <- glmQLFit(y, design = design, prior.count = prior_count)
        
        # extract results
        # lrt <- glmLRT(fit, contrast = contrast)
        lrt <- glmQLFTest(fit, contrast = contrast)
        tt1 <- topTags(lrt, n = Inf, adjust.method = adjust_method,
                       sort.by = "none")$table
        tt2 <- tt1[rownames(count), ]
        
        
        if (sum(isZ)) {
            tt2c <- tt2[rep(1, sum(isZ)), ]
            rownames(tt2c) <- rowF
            tt2c[] <- NA
            tt2 <- rbind(tt2, tt2c)    
        }
    } else {
        tt2 <- NULL
    }
    
    
    
    return(tt2)
}


# runDA <- function(d_sce, 
#                   feature_on_row = TRUE,
#                   design = NULL, 
#                   contrast = NULL,
#                   normalize = TRUE, method = "TMM",
#                   adjust_method = "BH", 
#                   prior_count = 0.125,
#                   assay_num = NULL, 
#                   min_sample = NULL,
#                   group_column = "group") {
#     
#     # If not specified, the first table in the assays is used
#     if (is.null(assay_num)) {
#         assay_num <- 1
#     }
#     
#     
#     # analysis step
#     if (feature_on_row) {
#         # the count table
#         count <- assays(d_sce)[[assayNum]]
#         
#         # extract link data
#         ld <- rowLinks(d_sce)
#         
#         # add rownames
#         rownames(ld) <- rownames(count) <- ld$nodeLab_alias
#         
#         
#         # the sample size in the smaller group
#         sz <- min(table(colData(d_sce)[[group_column]]))
#         
#     } else {
#         # the count table
#         count <- t(assays(d_sce)[[assayNum]])
#         
#         # extract link data
#         ld <- colLinks(d_sce)
#         
#         # the sample size in the smaller group
#         sz <- min(table(rowData(d_sce)[[group_column]]))
#     }
#     count0 <- count
#     
#     if (!is.null(min_sample)) {
#         sz <- min_sample
#     } 
#     
#     isZ <- apply(count, 1, function(x) {
#         sum(x > 0) < sz
#     })
#     rowF <- rownames(count)[isZ]
#     count <- count[!isZ, ]
#     
#     # remove samples with library size equal to 0
#     islib <- apply(count, 2, sum) > 0
#     count <- count[, islib, drop = FALSE]
#     
#     # check whether there is data to run 
#     isGene <- nrow(count) > 0
#     gr <- experiment_info[islib, group_column]
#     isGroup <- length(unique(gr)) > 0
#     
#     # create the DGEList
#     libSize <- apply(count0[ld$isLeaf, ], 2, sum)
#     
#     y <- DGEList(count, remove.zeros = FALSE)
#     y$samples$lib.size <- libSize
#     
#     
#     # do normalisation
#     if (normalize) {
#         y <- calcNormFactors(y, method = method)
#     }
#     
#     # estimate dispersion
#     y <- estimateDisp(y, design = design)
#     
#     # build model
#     fit <- glmFit(y, design = design, prior.count = prior.count)
#     
#     # extract results
#     lrt <- glmLRT(fit, contrast = contrast)
#     tt1 <- topTags(lrt, n = Inf, adjust.method = adjust.method,
#                    sort.by = "none")$table
#     tt2 <- tt1[rownames(count), ]
#     
#     
#     if (sum(isZ)) {
#         tt2c <- tt2[rep(1, sum(isZ)), ]
#         rownames(tt2c) <- rowF
#         tt2c[] <- NA
#         tt2 <- rbind(tt2, tt2c)    
#     }
#     
#     # cbind with the link data
#     tt3 <- cbind(ld, tt2[rownames(ld), ])
#     
#     return(tt3)
# }



#' Create design matrix
#'
#' \code{.designMatrix} creates a design matrix by expanding factors to a set of
#' dummay variables and epanding interactions similarly.
#'
#'
#' \code{.designMatrix} creates a design matrix using the data extracted from
#' \code{data}. \code{cols} specifies the columns to extract.
#' \code{.designMatrix} is built on \code{\link[stats]{model.matrix}} with
#' \code{contrasts.arg = NULL}.
#'
#' @param data A \code{data.frame} or \code{DataFrame}.
#' @param cols A numeric vector. Specify columns to include in the design of
#' model matrix. Default is to include all columns.
#'
#' @importFrom stats model.matrix as.formula
#' @keywords internal
#' @return a matrix.
.designMatrix <- function(data, cols = NULL) {
    
    stopifnot(class(data) %in% c("data.frame", "DataFrame", "DFrame"))
    
    # if cols is null, use all columns.
    if (is.null(cols)) {
        cols <- seq_len(ncol(data))
    }
    
    # create design matrix
    terms <- colnames(data)[cols]
    
    formula <- as.formula(paste("~", paste(terms, collapse = " + ")))
    
    design <- model.matrix(formula, data = data)
    
    return(design)
}

